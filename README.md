Math108C final project worked by Yibo Liang, Ziqi (Michael) Wang, Chang Long, and Shenhuiyi Zhu. Our paper is attached below. <br />
[MATH108C__Final_Project.pdf](https://github.com/user-attachments/files/15989000/MATH108C__Final_Project.pdf)
<br />

<br />
Abstract: We applied PCA and SVD to perform dimensionality reduction on a dataset of celebrity faces. We also explored the concept of Eigenfaces, which are the eigenvectors obtained from the SVD of the centered dataset. By representing each image as a linear combination of Eigenfaces, we were able to compress the dataset significantly while preserving its essential features. However, we also observed that the quality of reconstruction depends on the number of principal components retained. With a higher number of components, we achieved better reconstructions, indicating that more information was retained in the compressed representation. This highlights the trade-off between compression and reconstruction quality in dimensionality reduction techniques. Additionally, we discussed the use of autoencoders for dimensionality reduction and highlighted their potential to capture nonlinear relationships in data. Overall, dimensionality reduction techniques offer powerful tools for feature extraction and data compression, with applications in various fields including computer vision, pattern recognition, and data analysis. <br />


